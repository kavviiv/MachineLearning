{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification model comparison (Iris dataset)\n",
    "#### การเปรียบเทียบความแม่นยำของ Classifier models หลายตัวพร้อมกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "120           6.9          3.2           5.7          2.3   virginica\n",
       "11            4.8          3.4           1.6          0.2      setosa\n",
       "108           6.7          2.5           5.8          1.8   virginica\n",
       "66            5.6          3.0           4.5          1.5  versicolor\n",
       "82            5.8          2.7           3.9          1.2  versicolor"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('https://raw.githubusercontent.com/mathawanup/master_dataset/master/iris.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['sepal_length', 'sepal_width', 'petal_length', 'petal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[cols] # features\n",
    "y=df['species'] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=test_size, \n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1: choose model e.g. model=LogisticRegression,model=KNeighborsClassifier\n",
    "\n",
    "step 2: fit model  model.fit(X_train, y_train)\n",
    "\n",
    "step 3: predict model.predict(X_test)\n",
    "\n",
    "step 4: score e.g. score metrics.confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression \n",
    "model=LogisticRegression(multi_class='auto',solver='newton-cg')\n",
    "model.fit(X_train, y_train) \n",
    "y_pred=model.predict(X_test) \n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier score = 0.9111111111111111\n",
      "[[12  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  3 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.83      0.94      0.88        16\n",
      "   virginica       0.93      0.82      0.87        17\n",
      "\n",
      "   micro avg       0.91      0.91      0.91        45\n",
      "   macro avg       0.92      0.92      0.92        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "--------------------------------------------------\n",
      "LogisticRegression score = 0.9111111111111111\n",
      "[[12  0  0]\n",
      " [ 0 14  2]\n",
      " [ 0  2 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.88      0.88      0.88        16\n",
      "   virginica       0.88      0.88      0.88        17\n",
      "\n",
      "   micro avg       0.91      0.91      0.91        45\n",
      "   macro avg       0.92      0.92      0.92        45\n",
      "weighted avg       0.91      0.91      0.91        45\n",
      "\n",
      "--------------------------------------------------\n",
      "GaussianNB score = 0.8888888888888888\n",
      "[[12  0  0]\n",
      " [ 0 13  3]\n",
      " [ 0  2 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.87      0.81      0.84        16\n",
      "   virginica       0.83      0.88      0.86        17\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        45\n",
      "   macro avg       0.90      0.90      0.90        45\n",
      "weighted avg       0.89      0.89      0.89        45\n",
      "\n",
      "--------------------------------------------------\n",
      "DecisionTreeClassifier score = 0.8666666666666667\n",
      "[[12  0  0]\n",
      " [ 0 12  4]\n",
      " [ 0  2 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.86      0.75      0.80        16\n",
      "   virginica       0.79      0.88      0.83        17\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        45\n",
      "   macro avg       0.88      0.88      0.88        45\n",
      "weighted avg       0.87      0.87      0.87        45\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "algo = [\n",
    "    [KNeighborsClassifier(), 'KNeighborsClassifier'],\n",
    "    [LogisticRegression(multi_class='auto',solver='newton-cg'), 'LogisticRegression'],\n",
    "    [GaussianNB(), 'GaussianNB']\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "for a in algo:\n",
    "    model=a[0] # step 1: choose model \n",
    "    model.fit(X_train, y_train) # step 2: fit\n",
    "    y_pred=model.predict(X_test) # step 3: predict\n",
    "    score=model.score(X_test, y_test)# step 4: score\n",
    "    \n",
    "  \n",
    "    print(f'{a[1]} score = {score}') \n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.911111</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.911111</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.911111</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score              classifier\n",
       "0  0.911111    KNeighborsClassifier\n",
       "1  0.911111      LogisticRegression\n",
       "2  0.888889              GaussianNB\n",
       "3  0.911111  DecisionTreeClassifier"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dscore=pd.DataFrame(model_score, columns=['score', 'classifier'])\n",
    "dscore # dscore.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
